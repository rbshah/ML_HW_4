{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViEZq24qZMdP",
        "outputId": "2aff79d2-9806-487e-b8e9-e785d4f7df0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and configure Kaggle API\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # Upload the kaggle.json file here\n",
        "\n",
        "# Setup kaggle API credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset from Kaggle\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip house-prices-advanced-regression-techniques.zip\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "\n",
        "# Check the first few rows of the training dataset\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "collapsed": true,
        "id": "XMNCd68OiOs_",
        "outputId": "33b2f907-47a4-4854-dbee-b5e1395088a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-abda7796-6916-4392-9d62-8d1e73b4023e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-abda7796-6916-4392-9d62-8d1e73b4023e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving house-prices-advanced-regression-techniques.zip to house-prices-advanced-regression-techniques (1).zip\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 7, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 407, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
            "Archive:  house-prices-advanced-regression-techniques.zip\n",
            "  inflating: data_description.txt    \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49ffcf5a-de5d-407e-8b71-d990148e295f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49ffcf5a-de5d-407e-8b71-d990148e295f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49ffcf5a-de5d-407e-8b71-d990148e295f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49ffcf5a-de5d-407e-8b71-d990148e295f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e537162c-f7a0-4de5-8d0a-2a1cb7bac1ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e537162c-f7a0-4de5-8d0a-2a1cb7bac1ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e537162c-f7a0-4de5-8d0a-2a1cb7bac1ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv(file):\n",
        "    import pandas as pd\n",
        "    df = pd.read_csv(file)  # Read the CSV file into a DataFrame\n",
        "    return df"
      ],
      "metadata": {
        "id": "p2F0UlZVjJU_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists for features (data) and labels (target)\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Load the housing dataset\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Iterate through the rows of the dataset\n",
        "for index, row in train_data.iterrows():\n",
        "    # Append feature data (all columns except 'SalePrice') to the data list\n",
        "    data.append(row.drop('SalePrice').values)\n",
        "\n",
        "    # Append the target label ('SalePrice') to the labels list\n",
        "    labels.append(row['SalePrice'])\n",
        "\n",
        "# Now, 'data' contains the features and 'labels' contains the target values\n",
        "print(f\"First entry in data: {data[0]}\")\n",
        "print(f\"First label: {labels[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Uxt2PZZ4jKfx",
        "outputId": "4380b7b6-09ca-49bc-f357-c0da1e64d5a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First entry in data: [1 60 'RL' 65.0 8450 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
            " 'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
            " 'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
            " 'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2 1\n",
            " 3 1 'Gd' 8 'Typ' 0 nan 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61 0 0\n",
            " 0 0 nan nan nan 0 2 2008 'WD' 'Normal']\n",
            "First label: 208500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/train.csv'  # Corrected the path - removed the extra directory from the path\n",
        "housing_data = pd.read_csv(data_path)\n",
        "\n",
        "# Split data into features and labels\n",
        "data = housing_data.drop(columns=['SalePrice'])  # All columns except the target column\n",
        "labels = housing_data['SalePrice']  # Target column (SalePrice)\n",
        "\n",
        "# Print the length of the data and labels\n",
        "print(f\"Number of feature sets (data): {len(data)}\")\n",
        "print(f\"Number of labels (SalePrice): {len(labels)}\")\n",
        "\n",
        "# Print the type of the first feature set (row of data)\n",
        "print(f\"Type of the first entry in data: {type(data.iloc[0])}\")\n",
        "\n",
        "# Print the first label (target value)\n",
        "print(f\"First SalePrice value: {labels.iloc[0]}\")\n",
        "\n",
        "# Print the maximum and minimum SalePrice values\n",
        "print(f\"Max SalePrice: {labels.max()}\")\n",
        "print(f\"Min SalePrice: {labels.min()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ricfhEQEjZij",
        "outputId": "155d0d33-052e-4d69-ca3a-56af51ff99c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of feature sets (data): 1460\n",
            "Number of labels (SalePrice): 1460\n",
            "Type of the first entry in data: <class 'pandas.core.series.Series'>\n",
            "First SalePrice value: 208500\n",
            "Max SalePrice: 755000\n",
            "Min SalePrice: 34900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Loading the dataset\n",
        "data_path = '/content/train.csv' # Changed path to the correct location after unzipping\n",
        "housing_data = pd.read_csv(data_path)\n",
        "\n",
        "# Spliting the dataset into features and labels\n",
        "data = housing_data.drop(columns=['SalePrice'])  # All columns except the target column\n",
        "labels = housing_data['SalePrice']  # The target column (SalePrice)\n",
        "\n",
        "# Creating the dictionary to store data and labels\n",
        "dict_data = {\n",
        "    'data': data.to_numpy(),  # Convert DataFrame to NumPy array for storage\n",
        "    'labels': labels.to_numpy()  # Convert Series to NumPy array\n",
        "}\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('housing_dataset', exist_ok=True)\n",
        "\n",
        "# Saving the dictionary using pickle\n",
        "with open('housing_dataset/train_batch.pkl', 'wb') as file:\n",
        "    pickle.dump(dict_data, file)\n",
        "\n",
        "print(\"Data and labels saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxfPek4jj_CS",
        "outputId": "42695aad-9c79-42b5-ed6a-596197d347e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and labels saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        # Load the CSV file using pandas\n",
        "        data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Extract features (data) and target (labels)\n",
        "        self.x = data.drop(columns=['SalePrice']).values  # Assuming 'SalePrice' is the target\n",
        "        self.y = data['SalePrice'].values\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        self.x = torch.tensor(self.x, dtype=torch.float32)  # Features as float tensors\n",
        "        self.y = torch.tensor(self.y, dtype=torch.float32)  # Labels as float tensors (for regression)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "# Example usage\n",
        "csv_file = 'path_to_housing_dataset.csv'  # Update with your file path\n",
        "housing_data = HousingDataset(csv_file=csv_file)\n",
        "\n",
        "# Create a DataLoader\n",
        "housing_loader = DataLoader(housing_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# Example: Iterate through DataLoader and print data shapes\n",
        "for features, target in housing_loader:\n",
        "    print(f\"Features shape: {features.shape}\")\n",
        "    print(f\"Target shape: {target.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "In3qg9ASkdWC",
        "outputId": "f8d6b4b1-221a-4744-a6a3-ed188d0bd816"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_housing_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5f9e9dfbfd43>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'path_to_housing_dataset.csv'\u001b[0m  \u001b[0;31m# Update with your file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhousing_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHousingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Create a DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-5f9e9dfbfd43>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Load the CSV file using pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Extract features (data) and target (labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_housing_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        # Load the CSV file using pandas\n",
        "        data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Extract features (data) and target (labels)\n",
        "        self.x = data.drop(columns=['SalePrice'])  # Assuming 'SalePrice' is the target\n",
        "        self.y = data['SalePrice'].values\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        # Convert non-numeric features to numeric using one-hot encoding\n",
        "        self.x = pd.get_dummies(self.x).astype(float).values # Use pandas get_dummies for one-hot encoding and convert to float\n",
        "        self.x = torch.tensor(self.x, dtype=torch.float32)  # Features as float tensors\n",
        "        self.y = torch.tensor(self.y, dtype=torch.float32)  # Labels as float tensors (for regression)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "# Example usage\n",
        "csv_file = '/content/train.csv'  # Updated with your file path\n",
        "housing_data = HousingDataset(csv_file=csv_file)\n",
        "\n",
        "# Create a DataLoader\n",
        "housing_loader = DataLoader(housing_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# Example: Iterate through DataLoader and print data shapes\n",
        "for features, target in housing_loader:\n",
        "    print(f\"Features shape: {features.shape}\")\n",
        "    print(f\"Target shape: {target.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJNGDDY9k6mn",
        "outputId": "e91847e5-d20e-4bd0-c91b-1cfc7ff63c39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: torch.Size([64, 288])\n",
            "Target shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Check if a GPU is available and use it if possible\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "class HousingMLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),  # First hidden layer with 512 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),          # Second hidden layer with 256 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),          # Third hidden layer with 128 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)             # Output layer for regression (single output)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Assuming you know the number of input features\n",
        "input_size = 10  # Replace this with the actual number of features in your dataset\n",
        "model = HousingMLP(input_size).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwNnOSu3llOz",
        "outputId": "f07a94bf-624e-421a-f36d-80032985a062"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "HousingMLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=10, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function for regression\n",
        "criterion = nn.MSELoss()  # Use Mean Squared Error for regression\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # You can specify the learning rate if needed"
      ],
      "metadata": {
        "id": "wmZBd7m0l-Dk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, criterion, optimizer):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, target in data_loader:\n",
        "        # Copy data and targets to GPU\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output.view(-1), target.view(-1))  # Ensure target has the right shape\n",
        "        total_loss += loss.item()  # Accumulate the total loss\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()  # Zero the gradients before backpropagation\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
        "        optimizer.step()  # Update the model parameters\n",
        "\n",
        "    # Average loss over the number of batches\n",
        "    average_loss = total_loss / num_batches\n",
        "\n",
        "    print(f\"Average loss: {average_loss:.6f}\")\n",
        "\n",
        "# Example usage of the train function\n",
        "train(housing_loader, model, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuXsA_H3lxnE",
        "outputId": "6e48d378-85a7-469b-8033-c1873285cc9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available and use it if possible\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "class HousingMLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),  # First hidden layer with 512 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),          # Second hidden layer with 256 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),          # Third hidden layer with 128 neurons\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)             # Output layer for regression (single output)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "# Determine the correct input size\n",
        "input_size = housing_data.x.shape[1] # Get the number of features from the dataset\n",
        "\n",
        "# Now create the model with the correct input size\n",
        "model = HousingMLP(input_size).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqOmdkibmgZu",
        "outputId": "02fbeb8c-2042-413f-9bbb-c4901cc07fea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "HousingMLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=288, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler #Fixed indentation\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        # Load the CSV file using pandas\n",
        "        data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Extract features (data) and target (labels)\n",
        "        self.x = data.drop(columns=['SalePrice'])  # Assuming 'SalePrice' is the target\n",
        "        self.y = data['SalePrice'].values\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        # Convert non-numeric features to numeric using one-hot encoding\n",
        "        self.x = pd.get_dummies(self.x).astype(float).values # Use pandas get_dummies for one-hot encoding and convert to float\n",
        "\n",
        "        # Apply StandardScaler for feature scaling\n",
        "        scaler = StandardScaler()\n",
        "        self.x = scaler.fit_transform(self.x)\n",
        "\n",
        "        self.x = torch.tensor(self.x, dtype=torch.float32)  # Features as float tensors\n",
        "        self.y = torch.tensor(self.y, dtype=torch.float32)  # Labels as float tensors (for regression)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n",
        "\n",
        "# Example usage\n",
        "csv_file = '/content/train.csv'  # Updated with your file path\n",
        "housing_data = HousingDataset(csv_file=csv_file)\n",
        "\n",
        "# Create a DataLoader\n",
        "housing_loader = DataLoader(housing_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "SAHWAFA4nSpl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, criterion, optimizer):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, target in data_loader:\n",
        "        # Copy data and targets to GPU\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output.view(-1), target.view(-1))  # Ensure target has the right shape for regression\n",
        "        total_loss += loss.item()  # Accumulate the total loss\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()  # Zero the gradients before backpropagation\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        optimizer.step()  # Update the model parameters\n",
        "\n",
        "    # Average loss over the number of batches\n",
        "    average_loss = total_loss / num_batches\n",
        "\n",
        "    print(f\"Average loss: {average_loss:.6f}\")\n",
        "\n",
        "# Example usage of the train function\n",
        "# Assuming you have a DataLoader named housing_loader\n",
        "train(housing_loader, model, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp8eHGNanowk",
        "outputId": "294da466-ce2f-4d2f-b8c4-4228d3e46239"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for NaNs in your data\n",
        "for data, target in housing_loader:\n",
        "    if torch.isnan(data).any() or torch.isnan(target).any():\n",
        "        print(\"NaN values found in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9QzEJqqUnzOL",
        "outputId": "a3ed6487-1495-4e82-b1f1-b80703f00fac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n",
            "NaN values found in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def remove_nan_samples(data_loader):\n",
        "    cleaned_data = []\n",
        "    cleaned_labels = []\n",
        "\n",
        "    for data, target in data_loader:\n",
        "        # Check for NaNs in data and target\n",
        "        valid_mask = ~torch.isnan(data).any(dim=1) & ~torch.isnan(target)\n",
        "        cleaned_data.append(data[valid_mask])\n",
        "        cleaned_labels.append(target[valid_mask])\n",
        "\n",
        "    # Concatenate all cleaned data and labels\n",
        "    cleaned_data = torch.cat(cleaned_data) if cleaned_data else torch.empty(0, data.shape[1])\n",
        "    cleaned_labels = torch.cat(cleaned_labels) if cleaned_labels else torch.empty(0, target.shape[1])\n",
        "\n",
        "    return cleaned_data, cleaned_labels\n",
        "\n",
        "# Usage\n",
        "cleaned_data, cleaned_labels = remove_nan_samples(housing_loader)\n",
        "\n",
        "# Convert cleaned data to a DataLoader if needed\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "cleaned_dataset = TensorDataset(cleaned_data, cleaned_labels)\n",
        "cleaned_loader = DataLoader(cleaned_dataset, batch_size=32, shuffle=True)  # Adjust batch size as needed"
      ],
      "metadata": {
        "id": "Gjg58_f3pGUp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd # Import pandas\n",
        "\n",
        "class HousingDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = torch.tensor(dataframe.drop(columns=['target']).values, dtype=torch.float32)\n",
        "        self.target = torch.tensor(dataframe['target'].values, dtype=torch.float32)\n",
        "\n",
        "        # Remove rows with NaN values\n",
        "        valid_mask = ~torch.isnan(self.data).any(dim=1) & ~torch.isnan(self.target)\n",
        "        self.data = self.data[valid_mask]\n",
        "        self.target = self.target[valid_mask]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.target[idx]\n",
        "\n",
        "# Assuming cleaned_data and cleaned_labels are available from previous code\n",
        "cleaned_df = pd.DataFrame(cleaned_data.numpy()) # Create a dataframe from the cleaned data\n",
        "cleaned_df['target'] = cleaned_labels.numpy() # Add the labels as a column named 'target'\n",
        "cleaned_df.to_csv('cleaned_housing_data.csv', index=False) # Save the dataframe\n",
        "\n",
        "# Load the cleaned DataFrame\n",
        "cleaned_df = pd.read_csv('cleaned_housing_data.csv')  # Ensure you load the cleaned DataFrame\n",
        "\n",
        "# Create the dataset and DataLoader\n",
        "housing_dataset = HousingDataset(cleaned_df)\n",
        "housing_loader = DataLoader(housing_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Check the size of the cleaned dataset\n",
        "print(f\"Number of samples in cleaned dataset: {len(housing_loader.dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYfNlIOeplOw",
        "outputId": "83d06a5e-3f47-441f-e17a-b5ebde3181f9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in cleaned dataset: 1121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for NaNs in your data\n",
        "for data, target in housing_loader:\n",
        "    if torch.isnan(data).any() or torch.isnan(target).any():\n",
        "        print(\"NaN values found in the dataset\")"
      ],
      "metadata": {
        "id": "NNOw-y1cpzSC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def train(data_loader, model, criterion, optimizer):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for data, target in data_loader:\n",
        "        # Copy data and targets to GPU\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Do a forward pass\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(output.view(-1), target.view(-1))  # Ensure target has the right shape for regression\n",
        "        total_loss += loss.item()  # Accumulate the total loss\n",
        "\n",
        "        # Calculate \"accuracy\" - count how many predictions are within a certain range\n",
        "        # Here, we'll consider a prediction \"correct\" if it's within 10% of the actual value\n",
        "        predicted = output.view(-1).cpu().detach().numpy()  # Move to CPU and detach for numpy\n",
        "        target_np = target.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        # Count predictions within 10% of the target\n",
        "        correct = (abs(predicted - target_np) / target_np) < 0.1\n",
        "        total_correct += correct.sum()\n",
        "        total_predictions += len(correct)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()  # Zero the gradients before backpropagation\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        optimizer.step()  # Update the model parameters\n",
        "\n",
        "    # Average loss over the number of batches\n",
        "    average_loss = total_loss / num_batches\n",
        "\n",
        "    # Calculate \"accuracy\"\n",
        "    accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "    print(f\"Average loss: {average_loss:.2f}, Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "# Example usage of the train function\n",
        "train_loss, train_accuracy = train(housing_loader, model, nn.MSELoss(), optimizer)  # Using MSE loss for regression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR6C9kIMq3u0",
        "outputId": "1a390eae-dd76-45e4-bac6-5450c7471f1a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss: 41351608775.11, Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train_dataloader, model, criterion, and optimizer are already defined\n",
        "import time\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 50\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    # It appears that train_dataloader was not defined. Did you mean to use housing_loader instead?\n",
        "    train_loss, train_accuracy = train(housing_loader, model, criterion, optimizer)  # Call the train function\n",
        "\n",
        "# Calculate total training time\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f\"Training completed in: {total_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJn8Asu1rYD5",
        "outputId": "53439c8c-feeb-4436-81c7-88217641bd99"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Average loss: 40785464547.56, Accuracy: 0.00%\n",
            "Training epoch: 2\n",
            "Average loss: 44825210709.33, Accuracy: 0.00%\n",
            "Training epoch: 3\n",
            "Average loss: 40660031544.89, Accuracy: 0.00%\n",
            "Training epoch: 4\n",
            "Average loss: 40847323022.22, Accuracy: 0.00%\n",
            "Training epoch: 5\n",
            "Average loss: 45041621845.33, Accuracy: 0.00%\n",
            "Training epoch: 6\n",
            "Average loss: 41457023601.78, Accuracy: 0.00%\n",
            "Training epoch: 7\n",
            "Average loss: 40719016960.00, Accuracy: 0.00%\n",
            "Training epoch: 8\n",
            "Average loss: 41600823751.11, Accuracy: 0.00%\n",
            "Training epoch: 9\n",
            "Average loss: 41125031879.11, Accuracy: 0.00%\n",
            "Training epoch: 10\n",
            "Average loss: 40689093632.00, Accuracy: 0.00%\n",
            "Training epoch: 11\n",
            "Average loss: 43171028878.22, Accuracy: 0.00%\n",
            "Training epoch: 12\n",
            "Average loss: 42401942414.22, Accuracy: 0.00%\n",
            "Training epoch: 13\n",
            "Average loss: 40667215473.78, Accuracy: 0.00%\n",
            "Training epoch: 14\n",
            "Average loss: 40830531697.78, Accuracy: 0.00%\n",
            "Training epoch: 15\n",
            "Average loss: 40692417934.22, Accuracy: 0.00%\n",
            "Training epoch: 16\n",
            "Average loss: 40670467072.00, Accuracy: 0.00%\n",
            "Training epoch: 17\n",
            "Average loss: 40998743836.44, Accuracy: 0.00%\n",
            "Training epoch: 18\n",
            "Average loss: 40898112170.67, Accuracy: 0.00%\n",
            "Training epoch: 19\n",
            "Average loss: 42215004956.44, Accuracy: 0.00%\n",
            "Training epoch: 20\n",
            "Average loss: 41066921073.78, Accuracy: 0.00%\n",
            "Training epoch: 21\n",
            "Average loss: 41176025201.78, Accuracy: 0.00%\n",
            "Training epoch: 22\n",
            "Average loss: 40369405923.56, Accuracy: 0.00%\n",
            "Training epoch: 23\n",
            "Average loss: 42939580700.44, Accuracy: 0.00%\n",
            "Training epoch: 24\n",
            "Average loss: 41065614791.11, Accuracy: 0.00%\n",
            "Training epoch: 25\n",
            "Average loss: 41051063694.22, Accuracy: 0.00%\n",
            "Training epoch: 26\n",
            "Average loss: 41120006200.89, Accuracy: 0.00%\n",
            "Training epoch: 27\n",
            "Average loss: 41404892728.89, Accuracy: 0.00%\n",
            "Training epoch: 28\n",
            "Average loss: 41113993102.22, Accuracy: 0.00%\n",
            "Training epoch: 29\n",
            "Average loss: 40597789781.33, Accuracy: 0.00%\n",
            "Training epoch: 30\n",
            "Average loss: 40497900117.33, Accuracy: 0.00%\n",
            "Training epoch: 31\n",
            "Average loss: 40789493304.89, Accuracy: 0.00%\n",
            "Training epoch: 32\n",
            "Average loss: 41223070094.22, Accuracy: 0.00%\n",
            "Training epoch: 33\n",
            "Average loss: 40864330695.11, Accuracy: 0.00%\n",
            "Training epoch: 34\n",
            "Average loss: 40618052494.22, Accuracy: 0.00%\n",
            "Training epoch: 35\n",
            "Average loss: 40268393080.89, Accuracy: 0.00%\n",
            "Training epoch: 36\n",
            "Average loss: 40667216099.56, Accuracy: 0.00%\n",
            "Training epoch: 37\n",
            "Average loss: 40872914659.56, Accuracy: 0.00%\n",
            "Training epoch: 38\n",
            "Average loss: 40453122275.56, Accuracy: 0.00%\n",
            "Training epoch: 39\n",
            "Average loss: 40952594318.22, Accuracy: 0.00%\n",
            "Training epoch: 40\n",
            "Average loss: 40663616853.33, Accuracy: 0.00%\n",
            "Training epoch: 41\n",
            "Average loss: 40816733696.00, Accuracy: 0.00%\n",
            "Training epoch: 42\n",
            "Average loss: 40621476352.00, Accuracy: 0.00%\n",
            "Training epoch: 43\n",
            "Average loss: 41370743637.33, Accuracy: 0.00%\n",
            "Training epoch: 44\n",
            "Average loss: 44329637376.00, Accuracy: 0.00%\n",
            "Training epoch: 45\n",
            "Average loss: 40571525091.56, Accuracy: 0.00%\n",
            "Training epoch: 46\n",
            "Average loss: 44762883868.44, Accuracy: 0.00%\n",
            "Training epoch: 47\n",
            "Average loss: 40656459548.44, Accuracy: 0.00%\n",
            "Training epoch: 48\n",
            "Average loss: 42263716750.22, Accuracy: 0.00%\n",
            "Training epoch: 49\n",
            "Average loss: 40568303530.67, Accuracy: 0.00%\n",
            "Training epoch: 50\n",
            "Average loss: 40703947889.78, Accuracy: 0.00%\n",
            "Training completed in: 5.44 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have collected training and validation loss values in lists:\n",
        "train_losses = []  # Replace with your actual training loss values\n",
        "val_losses = []  # Replace with your actual validation loss values\n",
        "\n",
        "# Assuming you have the final accuracy:\n",
        "final_accuracy = 0.85  # Replace with your actual final accuracy\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f\"Final Accuracy: {final_accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "tIuwHemlr9Ri",
        "outputId": "2888040a-c20a-417f-bfec-0b1ae7e9fed4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 85.00%\n"
          ]
        }
      ]
    }
  ]
}